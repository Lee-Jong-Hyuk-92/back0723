import os
from PIL import Image
import numpy as np
import torch
from ultralytics import YOLO
from ultralytics.data.augment import LetterBox
from ultralytics.utils.ops import scale_masks

# âœ… ëª¨ë¸ ë¡œë“œ
MODEL_PATH = os.path.join(os.path.dirname(__file__), 'disease0728_best.pt')
model = YOLO(MODEL_PATH)

# âœ… í´ë˜ìŠ¤ ì´ë¦„ (YOLO class index ê¸°ì¤€)
YOLO_CLASS_MAP = {
    0: "ì¶©ì¹˜ ì´ˆê¸°",
    1: "ì¶©ì¹˜ ì¤‘ê¸°",
    2: "ì¶©ì¹˜ ë§ê¸°",
    3: "ì‡ëª¸ ì—¼ì¦ ì´ˆê¸°",
    4: "ì‡ëª¸ ì—¼ì¦ ì¤‘ê¸°",
    5: "ì‡ëª¸ ì—¼ì¦ ë§ê¸°",
    6: "ì¹˜ì£¼ì§ˆí™˜ ì´ˆê¸°",
    7: "ì¹˜ì£¼ì§ˆí™˜ ì¤‘ê¸°",
    8: "ì¹˜ì£¼ì§ˆí™˜ ë§ê¸°"
}

# âœ… ìƒ‰ìƒ íŒ”ë ˆíŠ¸ (í´ë˜ìŠ¤ë³„ RGBA)
PALETTE = {
    0: (255, 255, 0, 220),     # ğŸŸ¡ ë…¸ë‘ (ì¶©ì¹˜ ì´ˆê¸°)
    1: (255, 165, 0, 220),     # ğŸŸ  ì£¼í™© (ì¶©ì¹˜ ì¤‘ê¸°)
    2: (255, 0, 0, 220),       # ğŸ”´ ë¹¨ê°• (ì¶©ì¹˜ ë§ê¸°)
    3: (144, 202, 249, 220),   # #90CAF9 (ì‡ëª¸ ì—¼ì¦ ì´ˆê¸°) 
    4: ( 30, 136, 229, 220),   # #1E88E5 (ì‡ëª¸ ì—¼ì¦ ì¤‘ê¸°) 
    5: ( 13,  71, 161, 220),   # #0D47A1 (ì‡ëª¸ ì—¼ì¦ ë§ê¸°) 
    6: (178, 255, 158, 220),   # #B2FF9E (ì¹˜ì£¼ì§ˆí™˜ ì´ˆê¸°) 
    7: (102, 187, 106, 220),   # #66BB6A (ì¹˜ì£¼ì§ˆí™˜ ì¤‘ê¸°) 
    8: ( 27,  94,  32, 220),   # #1B5E20 (ì¹˜ì£¼ì§ˆí™˜ ë§ê¸°) 
}

def predict_overlayed_image(pil_img: Image.Image):
    orig_w, orig_h = pil_img.size
    img_np = np.array(pil_img.convert("RGB"))

    # âœ… CLIì™€ ë™ì¼í•œ LetterBox ì „ì²˜ë¦¬
    lb = LetterBox(new_shape=(640, 640))
    img_lb = lb(image=img_np)
    img_tensor = torch.from_numpy(img_lb).permute(2, 0, 1).float().unsqueeze(0) / 255.0

    # âœ… ì¶”ë¡ 
    results = model(img_tensor, verbose=False)
    r = results[0]

    # âœ… íƒì§€ ì—†ìœ¼ë©´ ì›ë³¸ ë°˜í™˜
    if r.masks is None or len(r.boxes.cls) == 0:
        return pil_img.copy(), [], 0.0, os.path.basename(MODEL_PATH), "ê°ì§€ë˜ì§€ ì•ŠìŒ", []

    # âœ… ë§ˆìŠ¤í¬ ë³µì›
    if r.masks is not None:
        masks_data = r.masks.data
        if masks_data.ndim == 3:  # [N, H, W] â†’ [N, 1, H, W]
            masks_data = masks_data[:, None, :, :]
        r.masks.data = scale_masks(masks_data, (orig_h, orig_w))

    # âœ… ì›ë³¸ RGBA ë³µì‚¬
    overlay_img = pil_img.convert("RGBA")

    # âœ… ê° ë§ˆìŠ¤í¬ë¥¼ í•´ë‹¹ ìƒ‰ìƒìœ¼ë¡œë§Œ ë°˜íˆ¬ëª… ë®ê¸°
    for seg, cls_t in zip(r.masks.data.squeeze(1), r.boxes.cls):
        cls_id = int(cls_t.item())
        color = PALETTE.get(cls_id, (255, 255, 255, 128))  # ê¸°ë³¸ í°ìƒ‰
        mask = seg.cpu().numpy()
        mask_img = Image.fromarray((mask * 255).astype(np.uint8))
        color_layer = Image.new("RGBA", (orig_w, orig_h), color)
        overlay_img = Image.alpha_composite(
            overlay_img,
            Image.composite(color_layer, Image.new("RGBA", (orig_w, orig_h)), mask_img)
        )

    # âœ… í´ë˜ìŠ¤ëª… / ë°•ìŠ¤ ì¤‘ì‹¬ ê³„ì‚°
    detected_classes = r.boxes.cls.tolist()
    detected_class_names = [YOLO_CLASS_MAP.get(int(c), "Unknown") for c in detected_classes]

    box_centers = []
    for box in r.boxes.xyxy:
        x1, y1, x2, y2 = box.tolist()
        cx, cy = int((x1 + x2) / 2), int((y1 + y2) / 2)
        box_centers.append([cx, cy])

    return (
        overlay_img.convert("RGB"),
        box_centers,
        float(r.boxes.conf.mean().item()) if r.boxes is not None else 0.0,
        os.path.basename(MODEL_PATH),
        detected_class_names[0] if detected_class_names else "ê°ì§€ë˜ì§€ ì•ŠìŒ",
        detected_class_names
    )
