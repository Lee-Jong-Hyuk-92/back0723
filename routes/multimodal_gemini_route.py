from flask import Blueprint, request, jsonify, current_app
from bson import ObjectId
import google.generativeai as genai
from PIL import Image
import requests
from io import BytesIO
import os
import time
import logging

# âœ… Gemini ì „ìš© ë¡œê±° ì„¤ì •
gemini_logger = logging.getLogger("gemini_logger")
gemini_logger.setLevel(logging.INFO)

log_dir = os.path.join(os.path.dirname(__file__), "..", "logs")
os.makedirs(log_dir, exist_ok=True)
log_path = os.path.join(log_dir, "gemini_times.log")

if not gemini_logger.handlers:
    fh = logging.FileHandler(log_path, encoding='utf-8')
    formatter = logging.Formatter('%(asctime)s.%(msecs)03d [%(levelname)s] %(message)s', datefmt='%Y-%m-%d %H:%M:%S')
    fh.setFormatter(formatter)
    gemini_logger.addHandler(fh)

multimodal_gemini_bp = Blueprint('multimodal_gemini', __name__)

API_KEY = os.getenv("GEMINI_API_KEY")
genai.configure(api_key=API_KEY)
model = genai.GenerativeModel("gemini-1.5-flash-latest")


@multimodal_gemini_bp.route("/multimodal_gemini", methods=["POST"])
def handle_ai_opinion():
    start_time = time.perf_counter()

    data = request.get_json()

    mongo_client = current_app.extensions.get("mongo_client")
    collection = mongo_client.get_collection("inference_results")

    image_url = data.get("image_url")
    inference_result_id = data.get("inference_result_id")

    # ê°’ì´ ì—†ì„ ìˆ˜ë„ ìˆìœ¼ë‹ˆ ì•ˆì „í•˜ê²Œ ê¸°ë³¸ê°’ ì²˜ë¦¬
    model1_label = data.get("model1Label") or "ê°ì§€ë˜ì§€ ì•ŠìŒ"
    conf1 = float(data.get("model1Confidence") or 0.0)
    
    # âœ… ìˆ˜ì •ëœ ë¶€ë¶„: model2Labels ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ìŠµë‹ˆë‹¤.
    model2_labels = data.get("model2Labels", [])
    conf2 = float(data.get("model2Confidence") or 0.0)
    
    tooth_number = data.get("model3ToothNumber") or "Unknown"
    conf3 = float(data.get("model3Confidence") or 0.0)

    doc = collection.find_one({"_id": ObjectId(inference_result_id)})
    if not doc:
        return jsonify({"error": "í•´ë‹¹ ë¶„ì„ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 404

    # âœ… ë¬¸ì§„ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    survey_data = doc.get("survey", {}) or {}

    # ì´ë¯¸ ìƒì„±ëœ ì‘ë‹µì´ ìˆìœ¼ë©´ ìºì‹œ ë°˜í™˜
    if "AI_result" in doc:
        print("ğŸ“„ ê¸°ì¡´ AI_result ë°˜í™˜")
        return jsonify({"message": doc["AI_result"]})

    print("ğŸ” ê¸°ì¡´ AI_result ì—†ìŒ -> Gemini í˜¸ì¶œ ì‹œì‘")

    # âœ… 2. ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸°
    try:
        # NOTE: ë‚´ë¶€ ë³´í˜¸ ë¦¬ì†ŒìŠ¤ë¼ë©´ ì¸ì¦ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        img_resp = requests.get(image_url, verify=False)
        img_resp.raise_for_status()
        img = Image.open(BytesIO(img_resp.content))
    except Exception as e:
        print("âŒ ì´ë¯¸ì§€ ìš”ì²­ ì‹¤íŒ¨:", str(e))
        return jsonify({"error": f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {str(e)}", "url": image_url}), 400

    # âœ… 3. í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ë¬¸ì§„ í¬í•¨)
    # ë¬¸ì§„ì„ ê¹”ë”í•œ bullet í˜•íƒœë¡œ ë³€í™˜
    if isinstance(survey_data, dict) and survey_data:
        survey_lines = "\n".join([f"- {k}: {v}" for k, v in survey_data.items()])
    else:
        survey_lines = "ì œê³µë˜ì§€ ì•ŠìŒ"

    # âœ… ìˆ˜ì •ëœ ë¶€ë¶„: ìœ„ìƒ ë¼ë²¨ ë¦¬ìŠ¤íŠ¸ë¥¼ ì½¤ë§ˆë¡œ ì—°ê²°í•©ë‹ˆë‹¤.
    hygiene_summary = "ê°ì§€ë˜ì§€ ì•ŠìŒ"
    if model2_labels and len(model2_labels) > 0:
        hygiene_summary = ", ".join(model2_labels)

    prompt = f"""
ë„ˆëŠ” ì¹˜ê³¼ ì „ë¬¸ì˜ë¡œì„œ, í™˜ìì˜ ë¬¸ì§„ ì •ë³´ì™€ AI ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ 7ì¤„ ë‚´ì™¸ë¡œ ê°„ê²°í•˜ê²Œ í™˜ìì—ê²Œ ì „ë‹¬í•  ì†Œê²¬ì„ ì‘ì„±í•´ì¤˜. ë…¸ì¸ë“¤ë„ ì´í•´í•˜ê¸° ì‰¬ìš´ ìš©ì–´ë¥¼ ì‚¬ìš©í•´. ë§ˆì§€ë§‰ì—ëŠ” 1ì¤„ ê²°ë¡ ë„ ê°™ì´.

[ë¬¸ì§„ ì •ë³´]
{survey_lines}

[AI ë¶„ì„ ìš”ì•½]
- ì§ˆë³‘ ì˜ˆì¸¡: {model1_label}, í™•ì‹ ë„: {conf1:.2f}
- ìœ„ìƒ ì˜ˆì¸¡: {hygiene_summary}, í™•ì‹ ë„: {conf2:.2f}
- ì¹˜ì•„ ë²ˆí˜¸: {tooth_number}, í™•ì‹ ë„: {conf3:.2f}
"""
    # âœ… ì¶”ê°€: ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ë¡œê±°ë¡œ ì¶œë ¥
    gemini_logger.info(f"Generated Prompt for Gemini: \n{prompt}")

    # âœ… 4. Gemini ìš”ì²­
    try:
        response = model.generate_content([prompt, img])
        result_text = response.text

        # âœ… ë©´ì±… ì¡°í•­ì„ AI ì‘ë‹µì— ì¶”ê°€
        disclaimer = "\n\nì£¼ì˜: ì´ AI ì†Œê²¬ì€ ì°¸ê³ ìš©ì´ë©°, ì‹¤ì œ ì¹˜ê³¼ ì§„ë£Œë¥¼ ëŒ€ì²´í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìµœì¢… ì§„ë‹¨ ë° ì¹˜ë£Œ ê³„íšì€ ë°˜ë“œì‹œ ì¹˜ê³¼ ì˜ì‚¬ì™€ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
        final_result = result_text.strip() + disclaimer

        # âœ… ê²°ê³¼ ì €ì¥
        collection.update_one(
            {"_id": ObjectId(inference_result_id)},
            {"$set": {"AI_result": final_result}}
        )

        elapsed_time_ms = int((time.perf_counter() - start_time) * 1000)
        gemini_logger.info(f"[ğŸ§  Gemini ë©€í‹°ëª¨ë‹¬ ì¶”ë¡  ì‹œê°„] {elapsed_time_ms}ms (inference_result_id={inference_result_id})")

        print("âœ… Gemini ì‘ë‹µ ì €ì¥ ì™„ë£Œ")
        return jsonify({"message": final_result})

    except Exception as e:
        print("âŒ Gemini í˜¸ì¶œ ì‹¤íŒ¨:", str(e))
        return jsonify({"error": f"Gemini í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}"}), 500